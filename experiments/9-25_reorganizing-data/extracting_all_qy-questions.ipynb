{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_posts = pd.read_csv('/nas/home/jwei/biases/rtgender/reddit_posts.csv')\n",
    "facebook_public_figures = pd.read_csv('/nas/home/jwei/biases/rtgender/facebook_wiki_posts.csv')\n",
    "facebook_politicians = pd.read_csv('/nas/home/jwei/biases/rtgender/facebook_congress_posts.csv')\n",
    "fitocracy_posts = pd.read_csv('/nas/home/jwei/biases/rtgender/fitocracy_posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_rule(sentence):\n",
    "    return sentence.endswith('?')\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def first_satisfies_rule(x, rule):\n",
    "    if not type(x) == str:\n",
    "        return None\n",
    "    \n",
    "    for x in sent_detector.tokenize(x):\n",
    "        if rule(x):\n",
    "            return x\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [reddit_posts, facebook_public_figures, facebook_politicians, fitocracy_posts]:\n",
    "    dataset['q'] = dataset.post_text.apply(lambda x: first_satisfies_rule(x, q_rule))\n",
    "    dataset['has_q'] = ~dataset.q.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_id</th>\n",
       "      <th>op_gender</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_type</th>\n",
       "      <th>q</th>\n",
       "      <th>has_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548219</th>\n",
       "      <td>18876566</td>\n",
       "      <td>M</td>\n",
       "      <td>548219</td>\n",
       "      <td>if you were giving President Obama a grade for his first 100 days -- what would it be?</td>\n",
       "      <td>status</td>\n",
       "      <td>if you were giving President Obama a grade for his first 100 days -- what would it be?</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           op_id op_gender  post_id  \\\n",
       "548219  18876566         M   548219   \n",
       "\n",
       "                                                                                     post_text  \\\n",
       "548219  if you were giving President Obama a grade for his first 100 days -- what would it be?   \n",
       "\n",
       "       post_type  \\\n",
       "548219    status   \n",
       "\n",
       "                                                                                             q  \\\n",
       "548219  if you were giving President Obama a grade for his first 100 days -- what would it be?   \n",
       "\n",
       "        has_q  \n",
       "548219   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_politicians[facebook_politicians.has_q].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision qy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_2(sentence):\n",
    "    if sentence is None:\n",
    "        return None\n",
    "    \n",
    "    keywords = ['do', 'does', 'did', 'are', 'is', 'was', 'should']\n",
    "    startswith = any(sentence.lower().startswith(i) for i in keywords)\n",
    "    return startswith and sentence.endswith('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [reddit_posts, facebook_public_figures, facebook_politicians, fitocracy_posts]:\n",
    "    dataset['is_qy'] = dataset.q.apply(rule_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(text, genders):\n",
    "    vectorizer = CountVectorizer(max_features=10000, min_df=10, binary=True, stop_words='english')\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    y = genders\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    lr = LogisticRegression(solver='lbfgs', max_iter=200).fit(X_train, y_train)\n",
    "    \n",
    "    acc = np.mean(lr.predict(X_test) == y_test)\n",
    "    \n",
    "    X = vectorizer.transform(text)\n",
    "    oov = (np.sum(X, axis=1)) < 1.\n",
    "    y = lr.predict_proba(X)[:,0] # probability scores\n",
    "    \n",
    "    features = sorted(list(zip([i for i in lr.coef_[0]], vectorizer.get_feature_names())), key=lambda x: x[0])\n",
    "    \n",
    "    return y, oov, acc, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/jwei/anaconda3/envs/biases/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M    0.786438\n",
      "W    0.213562\n",
      "Name: op_gender, dtype: float64\n",
      "0.7942478852519309\n",
      "Processing dataset...\n",
      "W    0.636587\n",
      "M    0.363413\n",
      "Name: op_gender, dtype: float64\n",
      "0.8609406952965235\n",
      "Processing dataset...\n",
      "M    0.778471\n",
      "W    0.221529\n",
      "Name: op_gender, dtype: float64\n",
      "0.8084924965893588\n",
      "Processing dataset...\n",
      "M    0.583724\n",
      "W    0.416276\n",
      "Name: op_gender, dtype: float64\n",
      "0.6217887725975262\n"
     ]
    }
   ],
   "source": [
    "for dataset in [reddit_posts, facebook_public_figures, facebook_politicians, fitocracy_posts]:\n",
    "    print('Processing dataset...')\n",
    "    dataset_questions = dataset[dataset.has_q]\n",
    "    scores, oov, acc, features = score(dataset_questions['post_text'], dataset_questions['op_gender'])\n",
    "\n",
    "    dataset.loc[dataset.has_q, 'oov'] = np.asarray(np.squeeze(oov))[0]\n",
    "    dataset.loc[dataset.has_q, 'q_score'] = scores\n",
    "    \n",
    "    dataset_questions = dataset[dataset.has_q]\n",
    "    print(dataset_questions.op_gender.value_counts(normalize=True))\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_id</th>\n",
       "      <th>op_gender</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>q</th>\n",
       "      <th>has_q</th>\n",
       "      <th>is_qy</th>\n",
       "      <th>oov</th>\n",
       "      <th>q_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for the follow!  I followed back :)  I wanna kick some butt, too :)  Let's do it!</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   op_id op_gender  post_id  \\\n",
       "0    102         W        0   \n",
       "\n",
       "                                                                                  post_text  \\\n",
       "0  Thanks for the follow!  I followed back :)  I wanna kick some butt, too :)  Let's do it!   \n",
       "\n",
       "      q  has_q is_qy  oov  q_score  \n",
       "0  None  False  None  NaN      NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in [('reddit', reddit_posts), ('facebook_public', facebook_public_figures), ('facebook_politicians', facebook_politicians), ('fitocracy', fitocracy_posts)]:\n",
    "    dataset[dataset.has_q] \\\n",
    "    .sort_values('q_score') \\\n",
    "    [['op_id', 'op_gender', 'post_id', 'q', 'is_qy', 'q_score', 'oov']] \\\n",
    "    .to_csv('%s_questions.tsv' % name, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
